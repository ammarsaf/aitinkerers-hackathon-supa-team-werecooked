{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tenacity import retry, stop_after_attempt, \\\n",
    "                     wait_random_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/faiq0913/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# set login credentials for Huggingface\n",
    "login('')\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Load, explore & clean Boolq dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['question', 'answer', 'passage'],\n",
       "     num_rows: 9427\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['question', 'answer', 'passage'],\n",
       "     num_rows: 3270\n",
       " }))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('google/boolq', split=('train', 'validation'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds[0].to_pandas()\n",
    "df_val = ds[1].to_pandas()\n",
    "\n",
    "df_train['answer'] = df_train['answer'].apply(lambda x: 0 if x == False else 1)\n",
    "df_val['answer'] = df_val['answer'].apply(lambda x: 0 if x == False else 1)\n",
    "\n",
    "df_train['language'] = 'English'\n",
    "df_val['language'] = 'English'\n",
    "\n",
    "df_train['split'] = 'train'\n",
    "df_val['split'] = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9427 entries, 0 to 9426\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  9427 non-null   object\n",
      " 1   answer    9427 non-null   int64 \n",
      " 2   passage   9427 non-null   object\n",
      " 3   language  9427 non-null   object\n",
      " 4   split     9427 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 368.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3270 entries, 0 to 3269\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  3270 non-null   object\n",
      " 1   answer    3270 non-null   int64 \n",
      " 2   passage   3270 non-null   object\n",
      " 3   language  3270 non-null   object\n",
      " 4   split     3270 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 127.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_json('../datasets/boolq-english-val.jsonl', orient='records', lines=True)\n",
    "df_train.to_json('../datasets/boolq-english-train.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Generate Malay translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewTranslatedOutput(BaseModel):\n",
    "    passage_my: str\n",
    "    question_my: str\n",
    "\n",
    "class OldTranslatedOutput(BaseModel):\n",
    "    question_my: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_done = {}\n",
    "\n",
    "# Define a function to handle when all retries fail\n",
    "def after_all_retries(retry_state):\n",
    "    print(retry_state.outcome.exception())\n",
    "    print(\"All retries failed. Moving on...\\n\")\n",
    "\n",
    "@retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_random_exponential(min=1, max=60),\n",
    "        retry_error_callback=after_all_retries,\n",
    ")\n",
    "def generate_reasoning(sample, split: str):\n",
    "    \"\"\"\n",
    "    A function that calls the OpenAI API to generate Malay translations and returns a dictionary.\n",
    "    \n",
    "    Here, we handle an instance where the 'passage' column (which is very long!) has been translated\n",
    "    already. If it hasn't we'll use the NewTranslatedOutput pydantic class as the output, else\n",
    "    we'll use the OldTranslatedOutput class. Gotta save those OpenAI credits!\n",
    "    \"\"\"\n",
    "\n",
    "    if sample['passage'] not in passage_done.keys():\n",
    "        prompt_new = f\"\"\"You are tasked with providing translations from English to\n",
    "            Bahasa Malaysia/Malay.\n",
    "\n",
    "            Passage (Input):\n",
    "            ```\n",
    "            {sample['passage']}\n",
    "            ```\n",
    "\n",
    "            Statement (Input):\n",
    "            ```\n",
    "            {sample['question']}\n",
    "            ```\n",
    "\n",
    "            Provide the output in JSON schema e.g., {{'passage_my': '', 'question_my': ''}}.\n",
    "            \"\"\"\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"NewTranslatedOutput\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"properties\": {\n",
    "                            'passage_my': {\"type\": \"string\"},\n",
    "                            'question_my': {\"type\": \"string\"},\n",
    "                        },\n",
    "                        \"required\": [\"question_my\", \"passage_my\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            },\n",
    "            temperature=0.2,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt_new},\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            # add the translated output as a key in the passage_done dictionary.\n",
    "            passage_done[sample['passage']] = NewTranslatedOutput.model_validate_json(completion.choices[0].message.content).passage_my\n",
    "\n",
    "            time.sleep(10)\n",
    "        \n",
    "            return {\n",
    "                'passage': NewTranslatedOutput.model_validate_json(completion.choices[0].message.content).passage_my,\n",
    "                'summary': NewTranslatedOutput.model_validate_json(completion.choices[0].message.content).question_my,\n",
    "                'answer': sample['answer'],\n",
    "                'language': 'Malay',\n",
    "                'split': split,\n",
    "            }\n",
    "        except ValidationError as e:\n",
    "            raise ValidationError(f\"Pydantic ValidationError: {e} - summary: {sample['summary']}\")\n",
    "            \n",
    "    else:\n",
    "        prompt_old = f\"\"\"You are tasked with providing translations from English to\n",
    "            Bahasa Malaysia/Malay.\n",
    "\n",
    "            Statement (Input):\n",
    "            ```\n",
    "            {sample['question']}\n",
    "            ```\n",
    "\n",
    "            Provide the output in JSON schema e.g., {{'question_my': ''}}.\n",
    "            \"\"\"\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"OldTranslatedOutput\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"properties\": {\n",
    "                            'question_my': {\"type\": \"string\"},\n",
    "                        },\n",
    "                        \"required\": [\"question_my\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            },\n",
    "            temperature=0.2,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt_old},\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            time.sleep(10)\n",
    "\n",
    "            return {\n",
    "                'passage': passage_done[sample['passage']],\n",
    "                'summary': OldTranslatedOutput.model_validate_json(completion.choices[0].message.content).question_my,\n",
    "                'answer': sample['answer'],\n",
    "                'language': 'Malay',\n",
    "                'split': split,\n",
    "            }\n",
    "        \n",
    "        except ValidationError as e:\n",
    "            raise ValidationError(f\"Pydantic ValidationError: {e} - summary: {sample['summary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5217a3ec99844de7b5e797231359ac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_val = []\n",
    "\n",
    "with open('../datasets/boolq-english-val.jsonl') as fopen:\n",
    "    for d in tqdm(fopen):\n",
    "        d = json.loads(d)\n",
    "        data_val.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3270\n"
     ]
    }
   ],
   "source": [
    "print(len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'did the girl in the lost world die',\n",
       " 'answer': 0,\n",
       " 'passage': \"On Isla Sorna, an island off the Pacific coast of Costa Rica, a young girl named Cathy Bowman wanders around during a family vacation, and survives an attack by a swarm of Compsognathus. Her parents file a lawsuit against the genetics company InGen, now headed by John Hammond's nephew, Peter Ludlow, who plans to use Isla Sorna to alleviate the financial losses imposed by the incident that occurred at Jurassic Park four years earlier. Mathematician Dr. Ian Malcolm meets Hammond at his mansion. Hammond explains that Isla Sorna, abandoned years earlier during a hurricane, is where InGen created their dinosaurs before moving them to Jurassic Park on Isla Nublar. Hammond hopes to stop InGen by sending a team to Isla Sorna to document the dinosaurs, thus causing public support against human interference on the island. Ian, who survived the Jurassic Park disaster, is reluctant. After learning that his girlfriend, paleontologist Dr. Sarah Harding, is part of the team and is already on Isla Sorna, Ian agrees to go to the island, but only to retrieve her.\",\n",
       " 'language': 'English'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage': 'Di Isla Sorna, sebuah pulau di pantai Pasifik Costa Rica, seorang gadis muda bernama Cathy Bowman berkeliaran semasa percutian keluarga, dan selamat daripada serangan sekumpulan Compsognathus. Ibu bapanya memfailkan saman terhadap syarikat genetik InGen, yang kini diketuai oleh anak saudara John Hammond, Peter Ludlow, yang merancang untuk menggunakan Isla Sorna untuk mengurangkan kerugian kewangan yang ditanggung akibat insiden yang berlaku di Jurassic Park empat tahun sebelumnya. Ahli matematik Dr. Ian Malcolm bertemu Hammond di rumah agamnya. Hammond menerangkan bahawa Isla Sorna, yang ditinggalkan bertahun-tahun lalu semasa ribut taufan, adalah tempat di mana InGen mencipta dinosaur mereka sebelum memindahkan mereka ke Jurassic Park di Isla Nublar. Hammond berharap untuk menghentikan InGen dengan menghantar satu pasukan ke Isla Sorna untuk mendokumentasikan dinosaur, dengan itu menyebabkan sokongan awam menentang campur tangan manusia di pulau itu. Ian, yang selamat daripada bencana Jurassic Park, enggan. Setelah mengetahui bahawa teman wanitanya, ahli paleontologi Dr. Sarah Harding, adalah sebahagian daripada pasukan dan sudah berada di Isla Sorna, Ian bersetuju untuk pergi ke pulau itu, tetapi hanya untuk mengambilnya.',\n",
       " 'summary': 'adakah gadis dalam dunia yang hilang mati',\n",
       " 'answer': 0,\n",
       " 'language': 'Malay',\n",
       " 'split': 'validation'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on one sample\n",
    "generate_reasoning(data_val[99], 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "data_val[99]['passage'] in passage_done.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Di Isla Sorna, sebuah pulau di pantai Pasifik Costa Rica, seorang gadis muda bernama Cathy Bowman berkeliaran semasa percutian keluarga, dan selamat daripada serangan sekumpulan Compsognathus. Ibu bapanya memfailkan saman terhadap syarikat genetik InGen, yang kini diketuai oleh anak saudara John Hammond, Peter Ludlow, yang merancang untuk menggunakan Isla Sorna untuk mengurangkan kerugian kewangan yang ditanggung akibat insiden yang berlaku di Jurassic Park empat tahun sebelumnya. Ahli matematik Dr. Ian Malcolm bertemu Hammond di rumah agamnya. Hammond menerangkan bahawa Isla Sorna, yang ditinggalkan bertahun-tahun lalu semasa ribut taufan, adalah tempat di mana InGen mencipta dinosaur mereka sebelum memindahkan mereka ke Jurassic Park di Isla Nublar. Hammond berharap untuk menghentikan InGen dengan menghantar satu pasukan ke Isla Sorna untuk mendokumentasikan dinosaur, dengan itu menyebabkan sokongan awam menentang campur tangan manusia di pulau itu. Ian, yang selamat daripada bencana Jurassic Park, enggan. Setelah mengetahui bahawa teman wanitanya, ahli paleontologi Dr. Sarah Harding, adalah sebahagian daripada pasukan dan sudah berada di Isla Sorna, Ian bersetuju untuk pergi ke pulau itu, tetapi hanya untuk mengambilnya.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "passage_done[data_val[99]['passage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_worker = 50\n",
    "passage_done = {}\n",
    "\n",
    "for i in tqdm(range(0, len(data_val), max_worker)):\n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate_reasoning, t, 'validation'): t for t in data_val[i: i + max_worker]}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                with open('../datasets/openai-generated/boolq-malay-val.jsonl', 'a') as final:\n",
    "                    json.dump(result, final)\n",
    "                    final.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77de6f1cf73d4e34ab8b873af18d22bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = []\n",
    "\n",
    "with open('../datasets/boolq-english-train.jsonl') as fopen:\n",
    "    for d in tqdm(fopen):\n",
    "        d = json.loads(d)\n",
    "        data_train.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b12e5e06e8e44f5a1743eb89e801c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'summary'\n",
      "All retries failed. Moving on...\n",
      "\n",
      "'summary'\n",
      "All retries failed. Moving on...\n",
      "\n",
      "'summary'\n",
      "All retries failed. Moving on...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "passage_done = {}\n",
    "\n",
    "for i in tqdm(range(0, len(data_train), max_worker)):\n",
    "    with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "        futures = {executor.submit(generate_reasoning, t, 'train'): t for t in data_train[i: i + max_worker]}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                with open('../datasets/openai-generated/boolq-malay-train.jsonl', 'a') as final:\n",
    "                    json.dump(result, final)\n",
    "                    final.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
