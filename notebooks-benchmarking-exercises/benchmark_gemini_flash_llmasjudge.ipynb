{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOU3KmV/yuREGOO0WBfyDDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "283bdd8c13174d529e674417373077b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6b9b8e5571e478f8af4357d83625859",
              "IPY_MODEL_0f47dba3818e489597f3dfb03bfa9b1a",
              "IPY_MODEL_4f26e8aa7aca41dca779fb0f6f478602"
            ],
            "layout": "IPY_MODEL_fe32ca31122544439331e46fc9b4e206"
          }
        },
        "c6b9b8e5571e478f8af4357d83625859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46359c5f37e74e1db6cd340102347041",
            "placeholder": "​",
            "style": "IPY_MODEL_035deb2beef146048631152ed65f4774",
            "value": ""
          }
        },
        "0f47dba3818e489597f3dfb03bfa9b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34578e1604be49b486a0da74ddaa24c6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ce94737a12a483f9e7e6c4814e56e1b",
            "value": 1
          }
        },
        "4f26e8aa7aca41dca779fb0f6f478602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cccb0e6cf84c4811afc786b65dd106c4",
            "placeholder": "​",
            "style": "IPY_MODEL_3ee83e8e253e4cd7939faa90347f5017",
            "value": " 200/? [00:00&lt;00:00, 6040.49it/s]"
          }
        },
        "fe32ca31122544439331e46fc9b4e206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46359c5f37e74e1db6cd340102347041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035deb2beef146048631152ed65f4774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34578e1604be49b486a0da74ddaa24c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3ce94737a12a483f9e7e6c4814e56e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cccb0e6cf84c4811afc786b65dd106c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee83e8e253e4cd7939faa90347f5017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3236c2611e9452bb7b881baeb2327e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae12414937594c2bb5229c6867e7b888",
              "IPY_MODEL_cc648575212544a4855b0848888c9f64",
              "IPY_MODEL_0287b51c2a3b41f988ae4f60c777ebf6"
            ],
            "layout": "IPY_MODEL_cde15ba2138f493d9fa603515176e2ce"
          }
        },
        "ae12414937594c2bb5229c6867e7b888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d6baecec36b4d53a2dda10acff0bff9",
            "placeholder": "​",
            "style": "IPY_MODEL_2c17239701314357ad176ec159238d81",
            "value": ""
          }
        },
        "cc648575212544a4855b0848888c9f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec516cf8cda4ede990eca7ab8f986d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07744613d343444985dcf7acabe45f1d",
            "value": 1
          }
        },
        "0287b51c2a3b41f988ae4f60c777ebf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab9ad731bf7a43678bf4fcf771df8cb6",
            "placeholder": "​",
            "style": "IPY_MODEL_a4d61cb6e1df46e6b6dd7ffcb736f49b",
            "value": " 200/? [00:00&lt;00:00, 5646.00it/s]"
          }
        },
        "cde15ba2138f493d9fa603515176e2ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6baecec36b4d53a2dda10acff0bff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c17239701314357ad176ec159238d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec516cf8cda4ede990eca7ab8f986d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "07744613d343444985dcf7acabe45f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab9ad731bf7a43678bf4fcf771df8cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d61cb6e1df46e6b6dd7ffcb736f49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a4627229ff94c79898eeaa853dcbc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9ccde4a1aaa49579f36d9a29707c65f",
              "IPY_MODEL_228db58c83344fd6a7a56db247311bee",
              "IPY_MODEL_2d727be04e3b43cebbb514037cfdf374"
            ],
            "layout": "IPY_MODEL_06db4ecbbe6046968f8b1737ec5dee67"
          }
        },
        "d9ccde4a1aaa49579f36d9a29707c65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf7a2544b2e42879149ec25153da23b",
            "placeholder": "​",
            "style": "IPY_MODEL_2cdd43fe70064f849894e9555a41f863",
            "value": ""
          }
        },
        "228db58c83344fd6a7a56db247311bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca5e6d656cf4fcd9fab488bdca3aea0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93cbacbb22ba49de8760307f08b8d324",
            "value": 1
          }
        },
        "2d727be04e3b43cebbb514037cfdf374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff890e10f2964cfeb82213237183ceb2",
            "placeholder": "​",
            "style": "IPY_MODEL_4bac6bed01ae46b192515116783dbee2",
            "value": " 200/? [00:00&lt;00:00, 6458.24it/s]"
          }
        },
        "06db4ecbbe6046968f8b1737ec5dee67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf7a2544b2e42879149ec25153da23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cdd43fe70064f849894e9555a41f863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ca5e6d656cf4fcd9fab488bdca3aea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "93cbacbb22ba49de8760307f08b8d324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff890e10f2964cfeb82213237183ceb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bac6bed01ae46b192515116783dbee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8e9b1d7a064618b11bc8d3eb55ebe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b631b9ffa18434399ed45d032c1402d",
              "IPY_MODEL_4ea5d63a6b5249bba020c2e5c3aa4fd4",
              "IPY_MODEL_bdec8f223a78486e98bd6246ac034807"
            ],
            "layout": "IPY_MODEL_52ba4d46e92045608a126a8ac4dff4e2"
          }
        },
        "9b631b9ffa18434399ed45d032c1402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e656de89afb542aaad5bf222d936b586",
            "placeholder": "​",
            "style": "IPY_MODEL_546b573d22634a7baa2f00312aadbff3",
            "value": ""
          }
        },
        "4ea5d63a6b5249bba020c2e5c3aa4fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7e423c8b544d14ade73236be38a6ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e41a17c7c6944f4e97b128e90551243c",
            "value": 1
          }
        },
        "bdec8f223a78486e98bd6246ac034807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02eb927141cc4848b7e30de07ad17def",
            "placeholder": "​",
            "style": "IPY_MODEL_40538ebc7048437cb8e4100e05e37a71",
            "value": " 200/? [00:00&lt;00:00, 6357.90it/s]"
          }
        },
        "52ba4d46e92045608a126a8ac4dff4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e656de89afb542aaad5bf222d936b586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546b573d22634a7baa2f00312aadbff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af7e423c8b544d14ade73236be38a6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e41a17c7c6944f4e97b128e90551243c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02eb927141cc4848b7e30de07ad17def": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40538ebc7048437cb8e4100e05e37a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3976c0918a28484eb937277933ee8286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4c970000ffb4077bdd6364070b46a96",
              "IPY_MODEL_e962612a8cae4532adcc1c7e58e38f08",
              "IPY_MODEL_fe4697b22b794cf486d8eda362fef26e"
            ],
            "layout": "IPY_MODEL_ecfa5566e30c4dd68836ce39986ebdc8"
          }
        },
        "b4c970000ffb4077bdd6364070b46a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e4c300bdbf41b09537b357dc4eebcd",
            "placeholder": "​",
            "style": "IPY_MODEL_291a70dc33484f3c89fca3a7b4fcaff3",
            "value": ""
          }
        },
        "e962612a8cae4532adcc1c7e58e38f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ca8bbf444740de8797907d67b50d18",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0290afcce2ac4e9fa4e0ff2c4fe09d15",
            "value": 1
          }
        },
        "fe4697b22b794cf486d8eda362fef26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a85840caa87e46cbad14a55738f1cb5d",
            "placeholder": "​",
            "style": "IPY_MODEL_c1d901e3c4c645488a3b29a270c41b22",
            "value": " 200/? [00:00&lt;00:00, 9882.44it/s]"
          }
        },
        "ecfa5566e30c4dd68836ce39986ebdc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e4c300bdbf41b09537b357dc4eebcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291a70dc33484f3c89fca3a7b4fcaff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9ca8bbf444740de8797907d67b50d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0290afcce2ac4e9fa4e0ff2c4fe09d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a85840caa87e46cbad14a55738f1cb5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d901e3c4c645488a3b29a270c41b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7bcc208d8544476b394b14a2bf57001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0e0201e51f645a58d0a60d96f6343e6",
              "IPY_MODEL_dd2252fc319c4793bf60ee7837cea0c1",
              "IPY_MODEL_2447bf91b53f46e08fd8c1649bf54a2f"
            ],
            "layout": "IPY_MODEL_bcfd5912984a4b83b34418a521e7b305"
          }
        },
        "b0e0201e51f645a58d0a60d96f6343e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37b863d5132d4fe6bd6bc77680e5ca5c",
            "placeholder": "​",
            "style": "IPY_MODEL_a28f271b3e5042039b7c015d57008f81",
            "value": ""
          }
        },
        "dd2252fc319c4793bf60ee7837cea0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4238cb7fe08a43c8bdcd5aa9d3366e66",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_515c0a3474df4a33a2c9a016f20f814e",
            "value": 1
          }
        },
        "2447bf91b53f46e08fd8c1649bf54a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5465653306b45019988b98cc9c3c177",
            "placeholder": "​",
            "style": "IPY_MODEL_6a8ca4d7696b49e2ba1dfa8c34b23e45",
            "value": " 200/? [00:00&lt;00:00, 8553.26it/s]"
          }
        },
        "bcfd5912984a4b83b34418a521e7b305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b863d5132d4fe6bd6bc77680e5ca5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a28f271b3e5042039b7c015d57008f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4238cb7fe08a43c8bdcd5aa9d3366e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "515c0a3474df4a33a2c9a016f20f814e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5465653306b45019988b98cc9c3c177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a8ca4d7696b49e2ba1dfa8c34b23e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammarsaf/aitinkerers-hackathon-supa-team-werecooked/blob/master/notebooks-benchmarking-exercises/benchmark_gemini_flash_llmasjudge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MbYKPeWf5E5R"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/wanadzhar913/aitinkerers-hackathon-supa-team-werecooked/refs/heads/master/datasets/for_presentation/boolq-eng-val-200.jsonl -q\n",
        "!wget https://raw.githubusercontent.com/wanadzhar913/aitinkerers-hackathon-supa-team-werecooked/refs/heads/master/datasets/for_presentation/boolq-malay-val-200.jsonl -q\n",
        "!wget https://raw.githubusercontent.com/wanadzhar913/aitinkerers-hackathon-supa-team-werecooked/refs/heads/master/datasets/for_presentation/fib-eng-val-200.jsonl -q\n",
        "!wget https://raw.githubusercontent.com/wanadzhar913/aitinkerers-hackathon-supa-team-werecooked/refs/heads/master/datasets/for_presentation/fib-malay-val-200.jsonl -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install weave flash_attn accelerate bitsandbytes -U -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jASYwfSIwhCQ",
        "outputId": "90b1fea5-2fc1-4f73-b739-19e2585ef2e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/2.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_APIKEY = userdata.get('GEMINI_APIKEY')\n",
        "WEAVE_APIKEY = userdata.get(\"WEAVE_APIKEY\")"
      ],
      "metadata": {
        "id": "uYUdv_q0xAHA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "ADzMYEQwxTyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os"
      ],
      "metadata": {
        "id": "V9ub63MtxWcw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=GEMINI_APIKEY)\n",
        "\n",
        "# model_gem = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "# response = model_gem.generate_content(\"Hello gemini who are you?\")\n",
        "# print(response.text)"
      ],
      "metadata": {
        "id": "KiNDAdfoxaRM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "ajrNxS4uyJFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import weave\n",
        "import re\n",
        "from typing import Dict"
      ],
      "metadata": {
        "id": "X2buyfwiyQUf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU agnostic"
      ],
      "metadata": {
        "id": "eRnB9xig0xPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6jLmdyF0y5I",
        "outputId": "35f714af-1a7c-4d50-d54c-d6380c879c6c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 21 03:16:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "LLm_dSXb00LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list = glob('*.jsonl')\n",
        "dataset_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jsV0bwAyRlf",
        "outputId": "99fbac81-5e57-431d-d7a5-f00b77149d49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['boolq-eng-val-200.jsonl',\n",
              " 'fib-eng-val-200.jsonl',\n",
              " 'boolq-malay-val-200.jsonl',\n",
              " 'fib-malay-val-200.jsonl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct Malay + English dataset\n",
        "data_all = []\n",
        "\n",
        "for k in dataset_list:\n",
        "    with open(k) as fopen:\n",
        "        for d in tqdm(fopen):\n",
        "            d = json.loads(d)\n",
        "            data_all.append(d)\n",
        "\n",
        "print(f'Size of dataset: {len(data_all)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "283bdd8c13174d529e674417373077b3",
            "c6b9b8e5571e478f8af4357d83625859",
            "0f47dba3818e489597f3dfb03bfa9b1a",
            "4f26e8aa7aca41dca779fb0f6f478602",
            "fe32ca31122544439331e46fc9b4e206",
            "46359c5f37e74e1db6cd340102347041",
            "035deb2beef146048631152ed65f4774",
            "34578e1604be49b486a0da74ddaa24c6",
            "3ce94737a12a483f9e7e6c4814e56e1b",
            "cccb0e6cf84c4811afc786b65dd106c4",
            "3ee83e8e253e4cd7939faa90347f5017",
            "b3236c2611e9452bb7b881baeb2327e5",
            "ae12414937594c2bb5229c6867e7b888",
            "cc648575212544a4855b0848888c9f64",
            "0287b51c2a3b41f988ae4f60c777ebf6",
            "cde15ba2138f493d9fa603515176e2ce",
            "2d6baecec36b4d53a2dda10acff0bff9",
            "2c17239701314357ad176ec159238d81",
            "1ec516cf8cda4ede990eca7ab8f986d3",
            "07744613d343444985dcf7acabe45f1d",
            "ab9ad731bf7a43678bf4fcf771df8cb6",
            "a4d61cb6e1df46e6b6dd7ffcb736f49b",
            "2a4627229ff94c79898eeaa853dcbc62",
            "d9ccde4a1aaa49579f36d9a29707c65f",
            "228db58c83344fd6a7a56db247311bee",
            "2d727be04e3b43cebbb514037cfdf374",
            "06db4ecbbe6046968f8b1737ec5dee67",
            "bdf7a2544b2e42879149ec25153da23b",
            "2cdd43fe70064f849894e9555a41f863",
            "4ca5e6d656cf4fcd9fab488bdca3aea0",
            "93cbacbb22ba49de8760307f08b8d324",
            "ff890e10f2964cfeb82213237183ceb2",
            "4bac6bed01ae46b192515116783dbee2",
            "8d8e9b1d7a064618b11bc8d3eb55ebe8",
            "9b631b9ffa18434399ed45d032c1402d",
            "4ea5d63a6b5249bba020c2e5c3aa4fd4",
            "bdec8f223a78486e98bd6246ac034807",
            "52ba4d46e92045608a126a8ac4dff4e2",
            "e656de89afb542aaad5bf222d936b586",
            "546b573d22634a7baa2f00312aadbff3",
            "af7e423c8b544d14ade73236be38a6ff",
            "e41a17c7c6944f4e97b128e90551243c",
            "02eb927141cc4848b7e30de07ad17def",
            "40538ebc7048437cb8e4100e05e37a71"
          ]
        },
        "id": "Eq092v4dyVYX",
        "outputId": "a51729c0-362a-45a1-9870-adbbc10cd303"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "283bdd8c13174d529e674417373077b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3236c2611e9452bb7b881baeb2327e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a4627229ff94c79898eeaa853dcbc62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d8e9b1d7a064618b11bc8d3eb55ebe8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of dataset: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_all[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3LCaBmSzKvK",
        "outputId": "fac3d990-c4d1-4ca6-e697-fc60c2d38285"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'does ethanol take more energy make that produces',\n",
              " 'answer': 0,\n",
              " 'passage': \"All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\",\n",
              " 'language': 'English'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct Malay + English dataset\n",
        "data_malay = []\n",
        "\n",
        "for k in dataset_list:\n",
        "    if 'malay' in k:\n",
        "        with open(k) as fopen:\n",
        "            for d in tqdm(fopen):\n",
        "                d = json.loads(d)\n",
        "                data_malay.append(d)\n",
        "\n",
        "print(f'Size of dataset: {len(data_malay)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "3976c0918a28484eb937277933ee8286",
            "b4c970000ffb4077bdd6364070b46a96",
            "e962612a8cae4532adcc1c7e58e38f08",
            "fe4697b22b794cf486d8eda362fef26e",
            "ecfa5566e30c4dd68836ce39986ebdc8",
            "a3e4c300bdbf41b09537b357dc4eebcd",
            "291a70dc33484f3c89fca3a7b4fcaff3",
            "d9ca8bbf444740de8797907d67b50d18",
            "0290afcce2ac4e9fa4e0ff2c4fe09d15",
            "a85840caa87e46cbad14a55738f1cb5d",
            "c1d901e3c4c645488a3b29a270c41b22",
            "c7bcc208d8544476b394b14a2bf57001",
            "b0e0201e51f645a58d0a60d96f6343e6",
            "dd2252fc319c4793bf60ee7837cea0c1",
            "2447bf91b53f46e08fd8c1649bf54a2f",
            "bcfd5912984a4b83b34418a521e7b305",
            "37b863d5132d4fe6bd6bc77680e5ca5c",
            "a28f271b3e5042039b7c015d57008f81",
            "4238cb7fe08a43c8bdcd5aa9d3366e66",
            "515c0a3474df4a33a2c9a016f20f814e",
            "e5465653306b45019988b98cc9c3c177",
            "6a8ca4d7696b49e2ba1dfa8c34b23e45"
          ]
        },
        "id": "t7MA7PZkyw4A",
        "outputId": "e39998c6-477e-4b79-8f58-589b5fcc55ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3976c0918a28484eb937277933ee8286"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7bcc208d8544476b394b14a2bf57001"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of dataset: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_malay[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMwRYx1OynJo",
        "outputId": "ec0b04f3-41f3-4b46-c27a-1f83a131c160"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'bolehkah anda memandu di kanada dengan lesen AS',\n",
              " 'answer': 1,\n",
              " 'passage': 'Orang yang memandu masuk ke Kanada mesti mempunyai dokumen pendaftaran kenderaan mereka dan bukti insurans.',\n",
              " 'language': 'Malay'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weave"
      ],
      "metadata": {
        "id": "Flf5iOji3bEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = 'benchmark_gemini-1.5-flash_llmasajudge_v1'\n",
        "\n",
        "weave.init(PROJECT_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "ec0ZsNB23cdw",
        "outputId": "193baa6b-6087-4e18-9ac8-d747a660883b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please login to Weights & Biases (https://wandb.ai/) to continue:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: ammardev.\n",
            "View Weave data at https://wandb.ai/ammardev/benchmark_gemini-1-5-flash_llmasajudge_v1/weave\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weave.trace.weave_client.WeaveClient at 0x7d06a27ce080>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RjftnmcFv5Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking"
      ],
      "metadata": {
        "id": "c5TNlQUEzjGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_llm(message: str) -> str:\n",
        "    \"\"\"Function to call the LLM and generate output\"\"\"\n",
        "    model_gem = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "    response = model_gem.generate_content(message)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "19Doo78qzkPo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_data in data_all[:5]:\n",
        "    print(call_llm(prompt_v1.format(passage=test_data[\"passage\"], question=test_data[\"question\"])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "52I498S5EnEl",
        "outputId": "89c8fff4-d46d-45ad-e3e4-ff601ddb57f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'consistency': 0} \n",
            "\n",
            "{'consistency': 1} \n",
            "\n",
            "{'consistency': 1} \n",
            "\n",
            "{'consistency': 1} \n",
            "\n",
            "{'consistency': 1} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeminiFlashAsAJudge(weave.Model):\n",
        "    prompt: str\n",
        "\n",
        "    @weave.op\n",
        "    def create_message(self, passage: str, question: str):\n",
        "        return self.prompt.format(passage=passage, question=question)\n",
        "\n",
        "    @weave.op\n",
        "    def predict(self, passage:str, question:str):\n",
        "        message = self.create_message(passage, question)\n",
        "        return call_llm(message=message)"
      ],
      "metadata": {
        "id": "2PEnGOFT3X-g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model_output, answer):\n",
        "    try:\n",
        "        model_output = json.loads(model_output)\n",
        "        class_model_output = model_output.get('consistency', None)\n",
        "    except json.JSONDecodeError:\n",
        "        # to handle edge cases where the LLM outputs improper JSON like this: '1 {\"consistency\": 0'\n",
        "        match = re.search(r'\\\"consistency\\\":\\s*([01])', model_output)\n",
        "\n",
        "        if match:\n",
        "            number = match.group(1)\n",
        "            class_model_output = int(number)\n",
        "        else:\n",
        "            class_model_output = None\n",
        "    return {\"accuracy\": class_model_output == answer}\n"
      ],
      "metadata": {
        "id": "ozTRd5Vm4vlf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_data in data_all[:5]:\n",
        "    model_output = call_llm(prompt_v1.format(passage=test_data[\"passage\"], question=test_data[\"question\"]))\n",
        "    # print(model_output)\n",
        "    acc = accuracy(model_output, test_data['answer'])\n",
        "    print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "9onea0NEG8ON",
        "outputId": "f5fc1ec9-ea3b-444a-db47-51e93037147b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': False}\n",
            "{'accuracy': False}\n",
            "{'accuracy': False}\n",
            "{'accuracy': False}\n",
            "{'accuracy': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BinaryMetrics(weave.Scorer):\n",
        "    class_name: str\n",
        "    eps: float = 1e-8\n",
        "\n",
        "    @weave.op()\n",
        "    def summarize(self, score_rows) -> dict:\n",
        "        # filter out None rows, model may error out sometimes...\n",
        "        score_rows = [score for score in score_rows if score[\"correct\"] is not None]\n",
        "        # Compute f1, precision, recall\n",
        "        tp = sum([not score[\"negative\"] and score[\"correct\"] for score in score_rows])\n",
        "        fp = sum([not score[\"negative\"] and not score[\"correct\"] for score in score_rows])\n",
        "        fn = sum([score[\"negative\"] and not score[\"correct\"] for score in score_rows])\n",
        "        precision = tp / (tp + fp + self.eps)\n",
        "        recall = tp / (tp + fn + self.eps)\n",
        "        f1 = 2 * precision * recall / (precision + recall + self.eps)\n",
        "        result = {\"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "        return result\n",
        "\n",
        "    @weave.op()\n",
        "    def score(self, answer: dict, model_output: dict|str) -> dict:\n",
        "        try:\n",
        "            model_output = json.loads(model_output)\n",
        "            class_model_output = model_output.get(self.class_name, None)\n",
        "        except json.JSONDecodeError:\n",
        "            # to handle edge cases where the LLM outputs improper JSON like this: '1 {\"consistency\": 1'\n",
        "            match = re.search(r'\\\"consistency\\\":\\s*([01])', model_output)\n",
        "\n",
        "            if match:\n",
        "                number = match.group(1)\n",
        "                class_model_output = int(number)\n",
        "            else:\n",
        "                class_model_output = None\n",
        "        result = {\n",
        "            \"correct\": class_model_output == answer,\n",
        "            \"negative\": not class_model_output,\n",
        "        }\n",
        "        return result\n",
        "\n",
        "F1 = BinaryMetrics(class_name=\"consistency\")"
      ],
      "metadata": {
        "id": "aCuqeE524xSA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 1"
      ],
      "metadata": {
        "id": "sanHso4d40p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_v1 = \"\"\"Anda adalah pakar dalam mengesan ketidakkonsistenan fakta dan halusinasi. Anda akan diberi satu dokumen dan satu soalan. Baca\n",
        "dokumen dan soalan/kenyataan yang diberikan dengan teliti dan kenal pasti Ketidakkonsistenan Fakta (iaitu mana-mana soalan/kenyataan yang\n",
        "tidak disokong atau bercanggah dengan maklumat dalam dokumen).\n",
        "\n",
        "### Anda perlu memilih antara dua pilihan berikut:\n",
        "- Tidak Konsisten dengan Fakta: Jika mana-mana soalan/kenyataan tidak disokong, terjawab atau bercanggah dengan dokumen, labelkannya sebagai 0.\n",
        "- Konsisten dengan Fakta: Jika semua soalan/kenyataan disokong/terjawab oleh dokumen, labelkannya sebagai 1.\n",
        "\n",
        "### Sebagai contoh:\n",
        "Dokumen: \"Gajah adalah mamalia besar yang biasanya ditemui di Afrika dan Asia. Mereka hidup dalam kumpulan yang dikenali sebagai kawanan dan terkenal kerana mempunyai ingatan yang baik.\"\n",
        "\n",
        "Soalan/Kenyataan: \"Gajah adalah mamalia besar yang biasanya ditemui di Eropah.\"\n",
        "Jawapan: {{'consistency': 0}}\n",
        "\n",
        "Soalan/Kenyataan: \"Gajah adalah mamalia besar yang biasanya ditemui di Afrika dan Asia.\"\n",
        "Jawapan: {{'consistency': 1}}\n",
        "\n",
        "### Jawab berdasarkan dokumen dan soalan/kenyataan berikut:\n",
        "Dokumen: {passage}\n",
        "Soalan/Kenyataan: {question}\n",
        "\n",
        "Kembalikan jawapan dalam format JSON untuk pilihan yang diberikan. Sebagai contoh: {{'consistency': 1}} atau {{'consistency': 0}}\"\"\""
      ],
      "metadata": {
        "id": "zWBJIbWk45mA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geminiflash_asjudge = GeminiFlashAsAJudge(prompt=prompt_v1)"
      ],
      "metadata": {
        "id": "ioi6NY8x476L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QV-RcOYc5IRP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "z7VjP4es5NyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## all data"
      ],
      "metadata": {
        "id": "gdKIUwqg5U-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_all = weave.Evaluation(dataset=data_all, scorers=[accuracy, F1])"
      ],
      "metadata": {
        "id": "ZEnUevQe5PoH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await evaluation_all.evaluate(geminiflash_asjudge)"
      ],
      "metadata": {
        "id": "5x69IjIK5TCp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9c0fbd0-7f97-4e2e-961d-a4a84b598dfd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 712.55ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 705.55ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1132.76ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 730.78ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.79ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 705.40ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1008.66ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.86ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2070.18ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m21\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m22\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.27ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m23\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1058.13ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1083.38ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.19ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2445.19ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m24\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m25\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m26\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m27\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.44ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.33ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m28\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m29\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m30\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m31\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m32\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m33\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m34\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m35\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m36\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m37\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m38\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m39\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m40\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m41\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m42\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m43\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m44\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m45\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m46\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2192.77ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.55ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m47\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m48\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m49\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1034.74ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.90ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m50\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m51\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.56ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1107.59ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.45ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.03ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2468.13ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1086.02ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.66ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2517.11ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m52\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m53\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m54\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m55\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m56\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m57\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m58\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m59\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m60\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m61\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m62\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m63\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m64\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m65\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m66\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m67\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m68\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m69\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m70\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m71\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m72\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 706.45ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m73\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m74\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m75\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m76\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m77\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m78\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m79\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.84ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m80\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1082.96ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.37ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 781.36ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2317.38ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2038.82ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1761.73ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2467.56ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2390.14ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m81\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m82\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m83\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m84\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m85\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m86\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m87\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m88\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m89\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3424.19ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 5, in call_llm\n",
            "    return response.text\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 484, in text\n",
            "    raise ValueError(\n",
            "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: MEDIUM\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: MEDIUM\n",
            "])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m90\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m91\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m92\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m93\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1384.25ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m94\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m95\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m96\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m97\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m98\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m99\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m100\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m101\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m102\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m103\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m104\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m105\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m106\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">106</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1359.87ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2420.33ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m107\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m108\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m109\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m110\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m111\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m112\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m113\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m114\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m115\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">115</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m116\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m117\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">117</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m118\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">118</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m119\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m120\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m121\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m122\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m123\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m124\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">124</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m125\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">125</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m126\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m127\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m128\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.84ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m129\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">129</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m130\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1209.15ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m131\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">131</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m132\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">132</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1136.45ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.96ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m133\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">133</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m134\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">134</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2443.08ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1086.77ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.15ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1107.69ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1058.56ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1112.48ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.65ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1637.60ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m135\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m136\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m137\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">137</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m138\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">138</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m139\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">139</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m140\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m141\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">141</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m142\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">142</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m143\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">143</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m144\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">144</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m145\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">145</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m146\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m147\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">147</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m148\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">148</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m149\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">149</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m150\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m151\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m152\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">152</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m153\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">153</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m154\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">154</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 708.91ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m155\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">155</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m156\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">156</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m157\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">157</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m158\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m159\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">159</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m160\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m161\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">161</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1135.88ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m162\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">162</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.57ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m163\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">163</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1112.73ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2546.41ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.89ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1087.12ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2419.76ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.73ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.09ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2444.57ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1083.77ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m164\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">164</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m165\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m166\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m167\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m168\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m169\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">169</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m170\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m171\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">171</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m172\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.33ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.81ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m173\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">173</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m174\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">174</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m175\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">175</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m176\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">176</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m177\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">177</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m178\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">178</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m179\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">179</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m180\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m181\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m182\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">182</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2064.61ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m183\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">183</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m184\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">184</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m185\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">185</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m186\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">186</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m187\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">187</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m188\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">188</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m189\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">189</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 5, in call_llm\n",
            "    return response.text\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 484, in text\n",
            "    raise ValueError(\n",
            "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: LOW\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: MEDIUM\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: LOW\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: MEDIUM\n",
            "])\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1085.57ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.54ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1300.84ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m190\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m191\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">191</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m192\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">192</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m193\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1262.49ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m194\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">194</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 708.74ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2495.97ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m195\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">195</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m196\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">196</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m197\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">197</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m198\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1059.20ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1135.52ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m199\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">199</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m200\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2393.79ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.14ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m201\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m202\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m203\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">203</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m204\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m205\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m206\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">206</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m207\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">207</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m208\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">208</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m209\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">209</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m210\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">210</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m211\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">211</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m212\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">212</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m213\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">213</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m214\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">214</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m215\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">215</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m216\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m217\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">217</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m218\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m219\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">219</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m220\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">220</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1085.44ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m221\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m222\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">222</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1271.25ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1159.84ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.23ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 756.34ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1082.96ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.27ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.62ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.54ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1334.75ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m223\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">223</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m224\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m225\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">225</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m226\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m227\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">227</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m228\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">228</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m229\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">229</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m230\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m231\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">231</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m232\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">232</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2393.86ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.76ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1536.43ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m233\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m234\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">234</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m235\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">235</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m236\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m237\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m238\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">238</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m239\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">239</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m240\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m241\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m242\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1209.43ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m243\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m244\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m245\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m246\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">246</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m247\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">247</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m248\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m249\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m250\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 832.05ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m251\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">251</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m252\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m253\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">253</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m254\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">254</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.36ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1183.67ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m255\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m256\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.31ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.64ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1662.26ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m257\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m258\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">258</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m259\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">259</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1111.67ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 733.03ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1259.02ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1209.24ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.07ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1136.42ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 5, in call_llm\n",
            "    return response.text\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 484, in text\n",
            "    raise ValueError(\n",
            "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: LOW\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: MEDIUM\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: LOW\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: MEDIUM\n",
            "])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m260\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">260</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m261\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">261</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m262\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">262</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m263\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">263</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m264\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">264</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m265\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">265</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m266\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">266</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m267\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m268\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">268</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m269\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">269</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m270\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m271\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m272\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m273\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">273</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m274\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">274</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m275\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m276\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">276</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m277\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">277</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m278\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">278</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m279\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">279</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m280\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">280</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 705.58ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3372.53ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 756.61ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m281\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">281</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m282\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">282</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m283\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">283</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m284\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m285\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">285</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m286\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 730.86ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1334.06ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1360.34ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m287\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">287</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m288\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">288</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m289\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">289</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m290\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2743.25ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1158.97ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1262.02ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2467.52ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m291\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">291</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m292\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m293\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">293</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m294\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">294</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m295\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">295</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m296\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">296</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m297\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">297</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m298\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">298</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m299\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">299</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m300\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m301\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">301</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m302\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">302</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m303\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">303</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 705.76ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2466.29ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m304\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">304</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m305\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">305</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m306\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">306</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m307\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">307</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m308\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m309\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">309</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m310\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">310</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m311\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">311</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m312\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m313\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">313</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1083.53ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2442.97ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.11ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m314\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m315\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m316\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">316</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1083.38ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 731.05ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.78ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1552.72ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m317\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">317</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m318\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">318</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m319\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">319</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m320\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m321\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">321</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 756.02ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m322\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m323\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">323</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m324\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">324</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m325\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">325</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m326\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m327\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">327</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m328\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">328</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m329\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">329</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m330\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">330</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m331\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">331</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m332\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m333\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">333</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m334\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">334</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m335\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">335</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m336\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">336</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m337\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">337</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2443.29ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m338\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">338</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m339\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">339</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m340\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1135.25ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m341\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">341</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.17ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1184.18ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m342\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m343\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">343</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 707.37ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m344\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">344</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m345\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">345</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.41ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2470.88ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.37ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.39ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m346\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">346</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m347\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">347</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m348\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">348</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m349\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">349</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m350\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">350</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m351\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">351</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m352\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">352</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m353\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">353</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m354\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">354</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m355\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">355</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m356\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">356</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m357\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">357</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m358\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">358</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m359\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">359</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m360\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">360</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m361\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">361</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m362\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 731.11ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.40ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.04ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m363\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">363</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m364\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">364</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m365\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">365</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m366\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">366</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m367\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m368\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">368</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 756.06ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1586.81ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1259.92ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m369\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m370\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">370</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m371\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">371</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m372\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2617.99ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1086.40ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.45ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2517.49ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.39ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1162.61ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2443.51ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1184.04ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1138.95ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m373\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m374\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">374</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m375\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">375</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m376\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">376</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m377\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">377</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m378\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">378</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m379\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">379</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m380\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">380</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m381\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">381</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m382\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">382</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m383\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">383</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m384\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m385\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">385</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m386\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">386</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m387\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">387</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m388\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m389\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">389</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m390\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">390</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m391\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">391</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m392\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">392</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m393\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">393</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m394\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">394</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m395\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">395</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m396\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">396</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2340.16ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 706.70ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m397\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">397</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m398\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">398</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m399\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">399</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m400\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m401\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1058.79ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1310.62ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m402\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m403\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">403</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2492.53ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.70ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.11ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m404\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">404</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m405\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">405</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m406\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">406</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1158.44ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m407\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">407</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m408\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m409\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">409</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m410\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">410</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m411\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">411</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m412\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">412</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m413\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m414\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">414</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m415\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">415</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m416\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">416</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m417\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">417</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m418\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">418</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m419\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">419</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m420\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m421\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">421</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m422\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">422</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 732.06ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 706.02ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m423\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">423</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m424\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m425\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">425</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m426\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">426</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m427\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.62ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.52ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m428\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">428</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m429\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">429</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1088.10ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.03ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1057.91ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2492.22ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1183.79ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 885.85ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1890.21ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m430\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">430</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m431\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">431</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m432\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">432</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m433\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">433</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m434\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">434</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m435\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">435</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m436\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">436</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m437\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">437</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1032.75ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2491.00ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m438\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m439\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">439</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m440\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">440</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m441\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">441</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m442\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">442</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m443\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">443</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m444\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">444</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m445\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">445</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m446\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">446</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m447\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">447</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 5, in call_llm\n",
            "    return response.text\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\", line 484, in text\n",
            "    raise ValueError(\n",
            "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: LOW\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: MEDIUM\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: NEGLIGIBLE\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: LOW\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: MEDIUM\n",
            "])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m448\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">448</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m449\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">449</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m450\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m451\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">451</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m452\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">452</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m453\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">453</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m454\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">454</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m455\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">455</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 706.76ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m456\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">456</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m457\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m458\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">458</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1288.72ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.88ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m459\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">459</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m460\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">460</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1084.80ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2442.30ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1184.89ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m461\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">461</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m462\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">462</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m463\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">463</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m464\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">464</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.46ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.80ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 857.37ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.53ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1058.23ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m465\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">465</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m466\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">466</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m467\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">467</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m468\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">468</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m469\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">469</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m470\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">470</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1216.33ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m471\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">471</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m472\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">472</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m473\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m474\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">474</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m475\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">475</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m476\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m477\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">477</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m478\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">478</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m479\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">479</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m480\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2089.69ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m481\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">481</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m482\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">482</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m483\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">483</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m484\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">484</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m485\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">485</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m486\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">486</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m487\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">487</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 757.09ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m488\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">488</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m489\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">489</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.29ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1107.97ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m490\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">490</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m491\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">491</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m492\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">492</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 757.18ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2466.70ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m493\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m494\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">494</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m495\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">495</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.18ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 731.50ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.65ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1311.62ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m496\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">496</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m497\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">497</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m498\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">498</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m499\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">499</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m500\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m501\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">501</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m502\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m503\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">503</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m504\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m505\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">505</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m506\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">506</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m507\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">507</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m508\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">508</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m509\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">509</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m510\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">510</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m511\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m512\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m513\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">513</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m514\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">514</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m515\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">515</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m516\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">516</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1107.95ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m517\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">517</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m518\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1082.87ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1139.13ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2492.04ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m519\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">519</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m520\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">520</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m521\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">521</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1159.73ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1988.55ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1536.08ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1183.35ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m522\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">522</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m523\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">523</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m524\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m525\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">525</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.49ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2499.66ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1586.58ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1234.80ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m526\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">526</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m527\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">527</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m528\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">528</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m529\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">529</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m530\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">530</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m531\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m532\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">532</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m533\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m534\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">534</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m535\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">535</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m536\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">536</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m537\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">537</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m538\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">538</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m539\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">539</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m540\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">540</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m541\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">541</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 757.56ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 755.61ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2492.12ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1485.63ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m542\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">542</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m543\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">543</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m544\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">544</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m545\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">545</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m546\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m547\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">547</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m548\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m549\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">549</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 730.90ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.20ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.37ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m550\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">550</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m551\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">551</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m552\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">552</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m553\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">553</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1111.20ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1160.57ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.62ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2440.95ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m554\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">554</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m555\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">555</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m556\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">556</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m557\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">557</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1561.34ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m558\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m559\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">559</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m560\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">560</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m561\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">561</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m562\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">562</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m563\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">563</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m564\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">564</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m565\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">565</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m566\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">566</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m567\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">567</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m568\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">568</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m569\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">569</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m570\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">570</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m571\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m572\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">572</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 756.59ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 731.26ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m573\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">573</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m574\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m575\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">575</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m576\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m577\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">577</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2494.12ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m578\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m579\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">579</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1135.31ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m580\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">580</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1082.68ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2467.27ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1183.47ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1284.15ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2498.00ms\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1184.57ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1539.72ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m581\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">581</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m582\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">582</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m583\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">583</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m584\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">584</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m585\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">585</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m586\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">586</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m587\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">587</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m588\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">588</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m589\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">589</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m590\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">590</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m591\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">591</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m592\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">592</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m593\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">593</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m594\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">594</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m595\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">595</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m596\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">596</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m597\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">597</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m598\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">598</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m599\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m600\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m601\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">601</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m602\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">602</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 806.51ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.63ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m603\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">603</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m604\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">604</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m605\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">605</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m606\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">606</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.03ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m607\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">607</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1160.68ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2492.22ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m608\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">608</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m609\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">609</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1082.85ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.12ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2491.23ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.26ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.98ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2493.19ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 781.60ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m610\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">610</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m611\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">611</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m612\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">612</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m613\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">613</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m614\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">614</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m615\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m616\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">616</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m617\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">617</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m618\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m619\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">619</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m620\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">620</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m621\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">621</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m622\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m623\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">623</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m624\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">624</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m625\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">625</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m626\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m627\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">627</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 958.20ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 782.18ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m628\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">628</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m629\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">629</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m630\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m631\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">631</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m632\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">632</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m633\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">633</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m634\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">634</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m635\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">635</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m636\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">636</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1638.58ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1310.54ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m637\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">637</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m638\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">638</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m639\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">639</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2469.57ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 732.17ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1135.18ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1109.90ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1134.72ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1110.72ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m640\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m641\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">641</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m642\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">642</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m643\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m644\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">644</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m645\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">645</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m646\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">646</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m647\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">647</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m648\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">648</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m649\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">649</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m650\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m651\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">651</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m652\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m653\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">653</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m654\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">654</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m655\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">655</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m656\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m657\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">657</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m658\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">658</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 732.35ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m659\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">659</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m660\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">660</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m661\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">661</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m662\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">662</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m663\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m664\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">664</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1108.78ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.67ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m665\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">665</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m666\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1235.81ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1485.96ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 758.09ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1184.08ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.27ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1159.99ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1359.14ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 806.10ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m667\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">667</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m668\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">668</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m669\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m670\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">670</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m671\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">671</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m672\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">672</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m673\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">673</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m674\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m675\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m676\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">676</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m677\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">677</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m678\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m679\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">679</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m680\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">680</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m681\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">681</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m682\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">682</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m683\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">683</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m684\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">684</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m685\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">685</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m686\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">686</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 730.74ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m687\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">687</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m688\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">688</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m689\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m690\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">690</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m691\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">691</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m692\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">692</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m693\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">693</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m694\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">694</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2770.60ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2114.93ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m695\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">695</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m696\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">696</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m697\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">697</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1060.75ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1309.76ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1133.79ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m698\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">698</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m699\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">699</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m700\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1132.99ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1158.62ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1158.58ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m701\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">701</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m702\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">702</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m703\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">703</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m704\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">704</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m705\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">705</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m706\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">706</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m707\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">707</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m708\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">708</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m709\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">709</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m710\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">710</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m711\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">711</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m712\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">712</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m713\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">713</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m714\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">714</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m715\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">715</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m716\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">716</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m717\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">717</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m718\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3019.74ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m719\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">719</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m720\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">720</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m721\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">721</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m722\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">722</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1765.69ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m723\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">723</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m724\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">724</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2618.65ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m725\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">725</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m726\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">726</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m727\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">727</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m728\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">728</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m729\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">729</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m730\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">730</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m731\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">731</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m732\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">732</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m733\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">733</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m734\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">734</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m735\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">735</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m736\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m737\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">737</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m738\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">738</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1762.15ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2574.24ms\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m739\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">739</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m740\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">740</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m741\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">741</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m742\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">742</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m743\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">743</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m744\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">744</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3502.74ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m745\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">745</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3097.64ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m746\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">746</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m747\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">747</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m748\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m749\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">749</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m750\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">750</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m751\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">751</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m752\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">752</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m753\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">753</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m754\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">754</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2139.77ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m755\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">755</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m756\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">756</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m757\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">757</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m758\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">758</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m759\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">759</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m760\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">760</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m761\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">761</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m762\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">762</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2718.60ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1791.75ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m763\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m764\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">764</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m765\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">765</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m766\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">766</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m767\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">767</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m768\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m769\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">769</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m770\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">770</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m771\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">771</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m772\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">772</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m773\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">773</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m774\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">774</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 881.58ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 191, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 54, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 344, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-15-9662f7da2ed0>\", line 11, in predict\n",
            "    return call_llm(message=message)\n",
            "  File \"<ipython-input-14-d582a2c57d5d>\", line 4, in call_llm\n",
            "    response = model_gem.generate_content(message)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 830, in generate_content\n",
            "    response = rpc(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
            "    _retry_error_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
            "    result = target()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 847, in __call__\n",
            "    raise core_exceptions.from_http_response(response)\n",
            "google.api_core.exceptions.TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m775\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">775</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m776\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">776</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m777\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">777</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m778\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">778</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m779\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">779</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m780\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">780</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m781\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">781</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m782\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">782</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m783\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">783</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m784\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m785\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">785</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 338, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 567, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 446, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 300, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 298, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 274, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 575, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 393, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 309, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 307, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-16-8426b6f3e9c4>\", line 3, in accuracy\n",
            "    model_output = json.loads(model_output)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 339, in loads\n",
            "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
            "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m786\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">786</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m787\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">787</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m788\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m789\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">789</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m790\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">790</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m791\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">791</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m792\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">792</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m793\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">793</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m794\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">794</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m795\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">795</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m796\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">796</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m797\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">797</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m798\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">798</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m799\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">799</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m800\u001b[0m of \u001b[1;36m800\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/ammardev/benchmark_gemini-1-5-flash_llmasajudge_v1/r/call/0192ac9f-1967-7192-8cc7-e43ee622db72\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'correct'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a0874380c68d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mevaluation_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeminiflash_asjudge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                     res, _ = await _do_call_async(\n\u001b[0m\u001b[1;32m    568\u001b[0m                         \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__should_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_do_call_async\u001b[0;34m(op, __weave, __should_raise, *args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mCoroutine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Call\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             )\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mexecute_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Call\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# long-term solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation summary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                     res, _ = await _do_call_async(\n\u001b[0m\u001b[1;32m    568\u001b[0m                         \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__should_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_do_call_async\u001b[0;34m(op, __weave, __should_raise, *args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mCoroutine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Call\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             )\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mexecute_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_call_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Call\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(self, eval_table)\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0mscorer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mscore_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscorer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mscored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscorer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     res, _ = _do_call(\n\u001b[0m\u001b[1;32m    576\u001b[0m                         \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__should_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(op, __weave, __should_raise, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             execute_result = _execute_call(\n\u001b[0m\u001b[1;32m    394\u001b[0m                 \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__should_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__should_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_execute_call\u001b[0;34m(__op, call, __should_raise, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\u001b[0m in \u001b[0;36m_execute_call\u001b[0;34m(__op, call, __should_raise, *args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1a2f6a13d90e>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(self, score_rows)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_rows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# filter out None rows, model may error out sometimes...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore_rows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Compute f1, precision, recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore_rows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1a2f6a13d90e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_rows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# filter out None rows, model may error out sometimes...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mscore_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore_rows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Compute f1, precision, recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore_rows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/weave/trace/vals.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mnew_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_trace_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'correct'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8t2Z4qQ10kug"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}